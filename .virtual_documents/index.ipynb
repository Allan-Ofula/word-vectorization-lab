


import pandas as pd
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
get_ipython().run_line_magic("matplotlib", " inline")
from sklearn.manifold import TSNE
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt', quiet=True)
np.random.seed(0)





filenames = [f"data/song{i}.txt" for i in range(1, 21)]





# Import and print song18.txt
with open('data/song18.txt') as f:
    test_song = f.readlines()
    
test_song








def clean_song(song):
    cleaned_lines = []
    for line in song:
        if not line.strip().startswith('['):  
            cleaned_lines.append(line.strip())
    joined_song = " ".join(cleaned_lines)
    
    for punct in ['"', ',', '.', "'", '?', '!', '(', ')', '\n']:
        joined_song = joined_song.replace(punct, "")
    
    return joined_song.lower()

clean_test_song = clean_song(test_song)
print(clean_test_song)





from nltk.tokenize import TreebankWordTokenizer

tokenizer = TreebankWordTokenizer()
tokenized_test_song = tokenizer.tokenize(clean_test_song)
print(tokenized_test_song[:20])








def count_vectorize(tokenized_song):
    word_counts = {}
    for word in tokenized_song:
        word_counts[word] = word_counts.get(word, 0) + 1
    return word_counts

test_vectorized = count_vectorize(tokenized_test_song)
print(test_vectorized)








import math
import os

def inverse_document_frequency(list_of_token_songs):
    import collections

    num_docs = len(list_of_token_songs)
    idf_counts = {}

    # Counting how many documents each word appears in
    for song in list_of_token_songs:
        unique_words = set(song)
        for word in unique_words:
            idf_counts[word] = idf_counts.get(word, 0) + 1

    # Calculating IDF score per word
    idf_dict = {}
    for word, count in idf_counts.items():
        idf_dict[word] = math.log(num_docs / (1 + count))  # Adding 1 to avoid division by zero

    return idf_dict





def tf_idf(list_of_token_songs):
    idf_dict = inverse_document_frequency(list_of_token_songs)
    tf_idf_list = []

    full_vocab = set(word for song in list_of_token_songs for word in song)

    for song in list_of_token_songs:
        tf_dict = count_vectorize(song)
        tf_idf_song = {}
        for word in full_vocab:
            tf = tf_dict.get(word, 0)
            idf = idf_dict.get(word, 0)
            tf_idf_song[word] = tf * idf
        tf_idf_list.append(tf_idf_song)

    return tf_idf_list





import re

def basic_tokenize(text):
    return re.findall(r'\b\w+\b', text.lower())


def main(filenames):
    songs_raw = []
    for fname in filenames:
        with open(fname, 'r', encoding='utf-8') as f:
            songs_raw.append(f.read())

    # Use basic tokenizer to avoid NLTK punkt issues
    tokenized_songs = [basic_tokenize(song) for song in songs_raw]

    tf_idf_vectors = tf_idf(tokenized_songs)
    return tf_idf_vectors





tf_idf_all_docs = main(filenames)

num_dims = len(tf_idf_all_docs[0])
print(f"Number of Dimensions: {num_dims}")





tf_idf_vals_list = [list(doc.values()) for doc in tf_idf_all_docs]

tf_idf_vals_list[0][:10]





from sklearn.manifold import TSNE
import numpy as np

t_sne_object_3d = TSNE(
    n_components=3,
    perplexity=19,
    learning_rate=200,
    init='random',
    random_state=13
)

transformed_data_3d = t_sne_object_3d.fit_transform(np.array(tf_idf_vals_list))
transformed_data_3d





t_sne_object_2d = TSNE(
    n_components=2,
    perplexity=19,
    learning_rate=200,
    init='random',
    random_state=13
)

transformed_data_2d = t_sne_object_2d.fit_transform(np.array(tf_idf_vals_list))
transformed_data_2d





kendrick_3d = transformed_data_3d[:10]
k3_x = [i[0] for i in kendrick_3d]
k3_y = [i[1] for i in kendrick_3d]
k3_z = [i[2] for i in kendrick_3d]

garth_3d = transformed_data_3d[10:]
g3_x = [i[0] for i in garth_3d]
g3_y = [i[1] for i in garth_3d]
g3_z = [i[2] for i in garth_3d]

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(k3_x, k3_y, k3_z, c='b', s=60, label='Kendrick')
ax.scatter(g3_x, g3_y, g3_z, c='red', s=60, label='Garth')
ax.view_init(40,10)
ax.legend()
plt.show()

kendrick_2d = transformed_data_2d[:10]
k2_x = [i[0] for i in kendrick_2d]
k2_y = [i[1] for i in kendrick_2d]

garth_2d = transformed_data_2d[10:]
g2_x = [i[0] for i in garth_2d]
g2_y = [i[1] for i in garth_2d]

fig = plt.figure(figsize=(20,10))
ax = fig.add_subplot(222)
ax.scatter(k2_x, k2_y, c='b', label='Kendrick')
ax.scatter(g2_x, g2_y, c='red', label='Garth')
ax.legend()
plt.show()





'''
The 3D and 2D graphs generated by t-SNE offer visual representations of the TF-IDF vectors, showing how songs cluster based on their word usage.

In the 3D graph:
- We can observe two relatively distinct clusters representing Kendrick Lamar and Garth Brooks songs.
- This suggests that the lyrical content of songs by each artist tends to be distinguishable based on word frequency and uniqueness.

In the 2D graph:
- Although it has fewer dimensions, we can still identify two clusters, though with slightly more overlap than the 3D one.
- This is expected due to dimensionality reduction compressing information.

Between the two, the 3D visualization is more informative because it preserves more structure from the high-dimensional space.

Overall, yes â€” TF-IDF successfully captures stylistic and lexical differences between the two artists, and t-SNE visualizations make those differences apparent.
'''



